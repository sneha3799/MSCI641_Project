{"cells":[{"cell_type":"markdown","metadata":{},"source":["# News Summarization"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>article</th>\n","      <th>highlights</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0001d1afc246a7964130f43ae940af6bc6c57f01</td>\n","      <td>By . Associated Press . PUBLISHED: . 14:11 EST...</td>\n","      <td>Bishop John Folda, of North Dakota, is taking ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0002095e55fcbd3a2f366d9bf92a95433dc305ef</td>\n","      <td>(CNN) -- Ralph Mata was an internal affairs li...</td>\n","      <td>Criminal complaint: Cop used his role to help ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00027e965c8264c35cc1bc55556db388da82b07f</td>\n","      <td>A drunk driver who killed a young woman in a h...</td>\n","      <td>Craig Eccleston-Todd, 27, had drunk at least t...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0002c17436637c4fe1837c935c04de47adb18e9a</td>\n","      <td>(CNN) -- With a breezy sweep of his pen Presid...</td>\n","      <td>Nina dos Santos says Europe must be ready to a...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0003ad6ef0c37534f80b55b4235108024b407f0b</td>\n","      <td>Fleetwood are the only team still to have a 10...</td>\n","      <td>Fleetwood top of League One after 2-0 win at S...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         id  \\\n","0  0001d1afc246a7964130f43ae940af6bc6c57f01   \n","1  0002095e55fcbd3a2f366d9bf92a95433dc305ef   \n","2  00027e965c8264c35cc1bc55556db388da82b07f   \n","3  0002c17436637c4fe1837c935c04de47adb18e9a   \n","4  0003ad6ef0c37534f80b55b4235108024b407f0b   \n","\n","                                             article  \\\n","0  By . Associated Press . PUBLISHED: . 14:11 EST...   \n","1  (CNN) -- Ralph Mata was an internal affairs li...   \n","2  A drunk driver who killed a young woman in a h...   \n","3  (CNN) -- With a breezy sweep of his pen Presid...   \n","4  Fleetwood are the only team still to have a 10...   \n","\n","                                          highlights  \n","0  Bishop John Folda, of North Dakota, is taking ...  \n","1  Criminal complaint: Cop used his role to help ...  \n","2  Craig Eccleston-Todd, 27, had drunk at least t...  \n","3  Nina dos Santos says Europe must be ready to a...  \n","4  Fleetwood top of League One after 2-0 win at S...  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["data = pd.read_csv('train.csv')\n","data.head()"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n","\n","                           \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n","\n","                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n","\n","                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n","\n","                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n","\n","                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n","\n","                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n","\n","                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n","\n","                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n","\n","                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n","\n","                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n","\n","                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n","\n","                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n","\n","                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n","\n","                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n","\n","                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n","\n","                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n","\n","                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n","\n","                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n","\n","                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n","\n","                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n","\n","                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n","\n","                           \"you're\": \"you are\", \"you've\": \"you have\"}"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":[" hi  . man tiger caller  walle\n"]}],"source":["import re\n","from nltk.corpus import stopwords\n","\n","stop_words = stopwords.words('english')\n","\n","def preprocess(text):\n","    text = text.lower() # lowercase\n","    text = text.split() # convert have'nt -> have not\n","    for i in range(len(text)):\n","        word = text[i]\n","        if word in contraction_mapping:\n","            text[i] = contraction_mapping[word]\n","    text = \" \".join(text)\n","    text = text.split()\n","    newtext = []\n","    for word in text:\n","        if word not in stop_words:\n","            newtext.append(word)\n","    text = \" \".join(newtext)\n","    text = text.replace(\"'s\",'') # convert your's -> your\n","    text = re.sub(r'\\(.*\\)','',text) # remove (words)\n","    text = re.sub(r'[^a-zA-Z0-9. ]','',text) # remove punctuations\n","    text = re.sub(r'\\.',' . ',text)\n","    return text\n","\n","sample = \"(hello) hi there .man tiger caller who's that isn't it ? WALL-E\"\n","print(preprocess(sample))"]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["roman shilov detained russian authorities without trial since july 2012  .  charged drug trafficking importing poppy seeds part father spice business  .  refused bail due considered flight risk  .  mr shilov brother wife baby daughter live brisbane  .  australian citizen awaited trial behind bars russian prison two years could face minimum 15 years jail supply poppy seeds .  roman shilov whose wife baby daughter live brisbane detained russian authorities charges drug trafficking july 2012 according abc .  never met daughter .  australian russian citizen refused bail due considered flight risk despite australian government assuring prosecutors would issued passport letter foreign affairs minister julie bishop revealed .  roman shilov whose wife baby daughter never chance meet live brisbane detained russian authorities controversial charges drug trafficking july 2012  .  regrettably russian authorities accepted advice remain committed mr shilov remain detention ms bishop wrote letter shilov family local mp .  letter also noted russian government refusing recognise mr shilov dual nationality turn eriously limits ability australian government provide consular assistance .  mr shilov returned moscow three years arrest assist father spice trade business supplied 20 per cent country poppy seed market time abc reported .  poppy seeds currently classified narcotics russian government .  australian russian citizen detained without trial two half years refused bail due considered flight risk despite australian government assuring prosecutors would issued passport  .  one charges laid shilov father russia federal drug control service importation 47 tonnes narcotics .  abc reported shipment made entirely poppy seeds service even admitted 0 . 001 percent could extracted narcotics .  evgeny shilov mr shilov brother also lives brisbane told abc minimum 15 year sentence worrying expressed concern brother detainment .  it seems very unfair put away day one let go said .  evgeny shilov mr shilov brother also lives brisbane told abc minimum 15 year sentence worrying one expressed concern brother long term detainment  .  im still hoping going get resolved .  all .  department foreign affairs told daily mail australia statement where concerns expressed mr shilov health welfare prison department made representations russian authorities .  consular officials also regular communication man family legal advisers case . \n"]}],"source":["data['highlights'] = data['highlights'][:100000].apply(lambda x:preprocess(x))\n","data['article'] = data['article'][:100000].apply(lambda x:preprocess(x))\n","print(data['highlights'][20],data['article'][20])"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["fears growing britain jails becoming hotbed extremism revealed today nearly half inmates one top security prison muslim .  42 per cent housed category whitemoor jail  quarter london prisons  consider islamic faith .  experts fear large numbers radicalised inside say spread jihadist ideas rife .  figures show quarter inmates london jails muslim one category jail revealing 42 per cent convicts follow islamic faith  .  whitemoor inmate zia al haq left jailed 18 planning bomb attacks london nezar hindawi right handed 45year sentence plotting blow jet  .  source cambridgeshire jail whitemoor told sunday people whitemoor effectively run muslims many jihadis .  2012 probe jail branded taliban recruiting ground said inmates offered protection converted religion .  shadow justice minister sadiq khan claimed ministers enough tackle issue radicalisation prisons .  said in jails like whitemoor chief inspector record warning risks radicalisation .  government needs wake problem late .  shadow justice secretary sadiq khan says little done tackle problem jails like whitemoor  .  source inside whitemoor said jail effectively run large muslim population  .  whitemoor houses terrorists including nezar hindawi given 45year sentence trying bomb airliner .  in jails like whitemoor chief inspector record warning risks radicalisation .  government needs wake problem late sadiq khan shadow justice minister  .  also jailed zia al haq locked 18 years 2007 offences including trying bomb london underground .  ministry justice insists prison wardens working hard tackle extremist ideologies .  prison service spokesman said last night prisoners held establishments suited managing individual needs level risk .  the recent independent inspection hmp whitemoor found safe environment praised staff professionalism dedicated care . \n","increasing muslim prison population highlighted whitemoor jail  .  one four convicts say islamic faith  .  fears trend growing radicalisation jihaists  .  shadow justice secretary sadiq khan calls government action  . \n"]}],"source":["x = data['article'][:100000]\n","y = data['highlights'][:100000]\n","print(x[50],y[50],sep='\\n')"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"data":{"text/plain":["0         .  associated press  .  published  .  1411 es...\n","1         decided move forward murder plot mata still r...\n","2        drunk driver killed young woman headon crash c...\n","3          breezy sweep pen president vladimir putin wr...\n","4        fleetwood team still 100 record sky bet league...\n","                               ...                        \n","99995     .  deni kirkova  .  published  .  0554 est 1 ...\n","99996    furious harvard business school professor gone...\n","99997     .  daily mail reporter  .  lewis dale 17 faci...\n","99998     .  daily mail reporter  .  published  .  1109...\n","99999     .  daily mail reporter  .  published  .  1803...\n","Name: article, Length: 100000, dtype: object"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["x"]},{"cell_type":"markdown","metadata":{},"source":["**Torch Req**"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata\n","import string\n","import re\n","import random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["SOS_token = 0\n","EOS_token = 1\n","\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[],"source":["def readLangs(text, summary, reverse=False):\n","    print(\"Reading lines...\")\n","    \n","    # Split every line into pairs and normalize\n","    pairs = [[text[i],summary[i]] for i in range(len(text))]\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(summary)\n","        output_lang = Lang(text)\n","    else:\n","        input_lang = Lang(text)\n","        output_lang = Lang(summary)\n","\n","    return input_lang, output_lang, pairs"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Reading lines...\n","Read 100000 sentence pairs\n","Counting words...\n","Counted words:\n","0         .  associated press  .  published  .  1411 es...\n","1         decided move forward murder plot mata still r...\n","2        drunk driver killed young woman headon crash c...\n","3          breezy sweep pen president vladimir putin wr...\n","4        fleetwood team still 100 record sky bet league...\n","                               ...                        \n","99995     .  deni kirkova  .  published  .  0554 est 1 ...\n","99996    furious harvard business school professor gone...\n","99997     .  daily mail reporter  .  lewis dale 17 faci...\n","99998     .  daily mail reporter  .  published  .  1109...\n","99999     .  daily mail reporter  .  published  .  1803...\n","Name: article, Length: 100000, dtype: object 336275\n","0        bishop john folda north dakota taking time dia...\n","1        criminal complaint cop used role help cocaine ...\n","2        craig ecclestontodd 27 drunk least three pints...\n","3        nina dos santos says europe must ready accept ...\n","4        fleetwood top league one 20 win scunthorpe  . ...\n","                               ...                        \n","99995    eleven innocent princesses raunch miley hallow...\n","99996    ben edelman associate professor business admin...\n","99997    lewis dale 17 weeps dock told faces lengthy ja...\n","99998    cctv shows driver chase man scooter swerve car...\n","99999    obama gave interview ahead super bowl new orle...\n","Name: highlights, Length: 100000, dtype: object 114479\n","['  roughly twoyear existence instagram trapped bounty inside mobile apps .  recently though photosharing service made chunks service available desktop users .  first could view page individual photos browser november added profile pages displayed user images .  tuesday finally see working version instagram feed online .  login instagram . com get replica instagram home screen photos everyone follow unfurling scroll browser window .  extra bells whistles here double click like image leave comments follow unfollow people .  unfortunately web version still missing important instagram feature ability upload photos .  company always put mobile first .  photos shared app meant taken builtin cameras mobile devices low resolution perfect match instagram grainy film filters .  facebookowned service becomes popular demand access devices even share photographs taken higherquality cameras .  company putting mobility speed ahead features .  our focus building mobileonly experience unique path chosen many reasons important instagram core seeing taking photos onthego said cofounder kevin systrom blog post announcing feature .  web interface missing parts familiar app users well .  explore page allows browse users hashtags there neither fun photomap feature lets see world user took photos .  thirdparty instagram client webstagram online version instagram feed .  though nearly attractive new official version still features missing instagram website including ability click hashtags see followers people following . ', 'photosharing service instagram lets see feed computer  .  users still cannot upload photos desktop browse hashtags  .  mobilefirst company rolling desktop features slowly past year  . ']\n"]}],"source":["input_lang, output_lang, pairs = prepareData( x, y , False)\n","print(random.choice(pairs))"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[],"source":["class EncoderRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(EncoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, input, hidden):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        output = embedded\n","        output, hidden = self.gru(output, hidden)\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["class DecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(DecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(output_size, hidden_size)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","        self.softmax = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, input, hidden):\n","        output = self.embedding(input).view(1, 1, -1)\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","        output = self.softmax(self.out(output[0]))\n","        return output, hidden\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["MAX_LENGTH = 3000"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["class AttnDecoderRNN(nn.Module):\n","    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","        super(AttnDecoderRNN, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.dropout_p = dropout_p\n","        self.max_length = max_length\n","\n","        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n","        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n","        self.dropout = nn.Dropout(self.dropout_p)\n","        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","        self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","    def forward(self, input, hidden, encoder_outputs):\n","        embedded = self.embedding(input).view(1, 1, -1)\n","        embedded = self.dropout(embedded)\n","\n","        attn_weights = F.softmax(\n","            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n","        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n","                                 encoder_outputs.unsqueeze(0))\n","\n","        output = torch.cat((embedded[0], attn_applied[0]), 1)\n","        output = self.attn_combine(output).unsqueeze(0)\n","\n","        output = F.relu(output)\n","        output, hidden = self.gru(output, hidden)\n","\n","        output = F.log_softmax(self.out(output[0]), dim=1)\n","        return output, hidden, attn_weights\n","\n","    def initHidden(self):\n","        return torch.zeros(1, 1, self.hidden_size, device=device)"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["def indexesFromSentence(lang, sentence):\n","    return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","\n","def tensorFromSentence(lang, sentence):\n","    indexes = indexesFromSentence(lang, sentence)\n","    indexes.append(EOS_token)\n","    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n","\n","\n","def tensorsFromPair(pair):\n","    input_tensor = tensorFromSentence(input_lang, pair[0])\n","    target_tensor = tensorFromSentence(output_lang, pair[1])\n","    return (input_tensor, target_tensor)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[],"source":["teacher_forcing_ratio = 0.5\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    input_length = input_tensor.size(0)\n","    target_length = target_tensor.size(0)\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","    loss = 0\n","\n","    for ei in range(input_length):\n","        encoder_output, encoder_hidden = encoder(\n","            input_tensor[ei], encoder_hidden)\n","        encoder_outputs[ei] = encoder_output[0, 0]\n","\n","    decoder_input = torch.tensor([[SOS_token]], device=device)\n","\n","    decoder_hidden = encoder_hidden\n","\n","    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","    if use_teacher_forcing:\n","        # Teacher forcing: Feed the target as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            loss += criterion(decoder_output, target_tensor[di])\n","            decoder_input = target_tensor[di]  # Teacher forcing\n","\n","    else:\n","        # Without teacher forcing: use its own predictions as the next input\n","        for di in range(target_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            topv, topi = decoder_output.topk(1)\n","            decoder_input = topi.squeeze().detach()  # detach from history as input\n","\n","            loss += criterion(decoder_output, target_tensor[di])\n","            if decoder_input.item() == EOS_token:\n","                break\n","\n","    loss.backward()\n","\n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","\n","    return loss.item() / target_length"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["import time\n","import math\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","\n","def showPlot(points):\n","    plt.figure()\n","    fig, ax = plt.subplots()\n","    # this locator puts ticks at regular intervals\n","    loc = ticker.MultipleLocator(base=0.2)\n","    ax.yaxis.set_major_locator(loc)\n","    plt.plot(points)"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[],"source":["plot_losses = []\n","def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=10, learning_rate=0.01):\n","    print(\"Training....\")\n","    start = time.time()\n","    \n","    print_loss_total = 0  # Reset every print_every\n","    plot_loss_total = 0  # Reset every plot_every\n","\n","    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","    training_pairs = [tensorsFromPair(random.choice(pairs))\n","                      for i in range(n_iters)]\n","    criterion = nn.NLLLoss()\n","\n","    for iter in range(1, n_iters + 1):\n","        if iter% 1000 == 0:\n","            print(iter,\"/\",n_iters + 1)\n","        training_pair = training_pairs[iter - 1]\n","        input_tensor = training_pair[0]\n","        target_tensor = training_pair[1]\n","        loss = train(input_tensor, target_tensor, encoder,\n","                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n","        print_loss_total += loss\n","        plot_loss_total += loss\n","\n","        if iter % print_every == 0:\n","            print_loss_avg = print_loss_total / print_every\n","            print_loss_total = 0\n","            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n","                                         iter, iter / n_iters * 100, print_loss_avg))\n","\n","        if iter % plot_every == 0:\n","            plot_loss_avg = plot_loss_total / plot_every\n","            plot_losses.append(plot_loss_avg)\n","            plot_loss_total = 0\n","\n","    showPlot(plot_losses)"]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["def evaluateSeq2Seq(encoder, decoder, sentence, max_length=MAX_LENGTH):\n","    with torch.no_grad():\n","        input_tensor = tensorFromSentence(input_lang, sentence)\n","        input_length = input_tensor.size()[0]\n","        encoder_hidden = encoder.initHidden()\n","\n","        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","        for ei in range(input_length):\n","            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n","                                                     encoder_hidden)\n","            encoder_outputs[ei] += encoder_output[0, 0]\n","\n","        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n","\n","        decoder_hidden = encoder_hidden\n","\n","        decoded_words = []\n","        decoder_attentions = torch.zeros(max_length, max_length)\n","\n","        for di in range(max_length):\n","            decoder_output, decoder_hidden, decoder_attention = decoder(\n","                decoder_input, decoder_hidden, encoder_outputs)\n","            decoder_attentions[di] = decoder_attention.data\n","            topv, topi = decoder_output.data.topk(1)\n","            if topi.item() == EOS_token:\n","                decoded_words.append('<EOS>')\n","                break\n","            else:\n","                decoded_words.append(output_lang.index2word[topi.item()])\n","\n","            decoder_input = topi.squeeze().detach()\n","\n","        return decoded_words, decoder_attentions[:di + 1]"]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["def evaluateRandomly(encoder, decoder, n=10):\n","    for i in range(n):\n","        pair = random.choice(pairs)\n","        print('>', pair[0])\n","        print('=', pair[1])\n","        output_words, attentions = evaluateSeq2Seq(encoder, decoder, pair[0])\n","        output_sentence = ' '.join(output_words)\n","        print('<', output_sentence)\n","        print('')"]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training....\n","2m 5s (- 36735m 3s) (10 0%) 11.1472\n","4m 5s (- 35750m 6s) (20 0%) 10.0585\n","6m 20s (- 37004m 22s) (30 0%) 6.9843\n","8m 10s (- 35757m 32s) (40 0%) 6.7800\n","10m 15s (- 35890m 29s) (50 0%) 6.5139\n","12m 26s (- 36256m 25s) (60 0%) 4.9557\n","14m 16s (- 35686m 50s) (70 0%) 5.7414\n","16m 35s (- 36265m 50s) (80 0%) 4.8637\n","19m 37s (- 38142m 58s) (90 0%) 4.7556\n","21m 22s (- 37393m 0s) (100 0%) 4.7503\n","23m 4s (- 36685m 30s) (110 0%) 5.3263\n","24m 36s (- 35869m 36s) (120 0%) 4.0672\n","27m 21s (- 36797m 24s) (130 0%) 5.4797\n","29m 46s (- 37197m 28s) (140 0%) 3.0841\n","31m 42s (- 36964m 29s) (150 0%) 6.1202\n","33m 32s (- 36655m 36s) (160 0%) 3.0891\n","35m 33s (- 36565m 33s) (170 0%) 5.0485\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m encoder1 \u001b[38;5;241m=\u001b[39m EncoderRNN(input_lang\u001b[38;5;241m.\u001b[39mn_words, hidden_size)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m attn_decoder1 \u001b[38;5;241m=\u001b[39m AttnDecoderRNN(hidden_size, output_lang\u001b[38;5;241m.\u001b[39mn_words, dropout_p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtrainIters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattn_decoder1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m175000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[22], line 21\u001b[0m, in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     19\u001b[0m input_tensor \u001b[38;5;241m=\u001b[39m training_pair[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     20\u001b[0m target_tensor \u001b[38;5;241m=\u001b[39m training_pair[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m---> 21\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m print_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n\u001b[1;32m     24\u001b[0m plot_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\n","Cell \u001b[0;32mIn[19], line 44\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m decoder_input\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m==\u001b[39m EOS_token:\n\u001b[1;32m     42\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m encoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     47\u001b[0m decoder_optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    524\u001b[0m     )\n\u001b[0;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/autograd/__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/homebrew/lib/python3.10/site-packages/torch/autograd/graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["hidden_size = 300\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 175000, print_every=10)"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[],"source":["torch.save(encoder1.state_dict(), 'seq2seq-news/enc.w')\n","torch.save(attn_decoder1.state_dict(), 'seq2seq-news/att.w')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":1835,"sourceId":3176,"sourceType":"datasetVersion"},{"datasetId":1895,"sourceId":791838,"sourceType":"datasetVersion"}],"dockerImageVersionId":29661,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
