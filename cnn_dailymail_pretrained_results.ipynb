{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec2e060",
   "metadata": {},
   "source": [
    "# News Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40faf34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/homebrew/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <9A4710B9-0DA3-36BB-9129-645F282E64B2> /opt/homebrew/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <7856C0E5-3D52-39C7-8515-71217150BD2E> /opt/homebrew/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datasets\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline, DataCollatorForSeq2Seq\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd92bace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the testing dataset\n",
    "df_test = pd.read_csv('train.csv')\n",
    "df_test = df_test.drop(columns=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b41f2d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters: 406290432\n",
      "Trainable Parameters: 406290432\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bart-news\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "# Create a summarization pipeline\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Extract model parameters\n",
    "def get_model_parameters(model):\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "total_params, trainable_params = get_model_parameters(model)\n",
    "print(f\"Total Parameters: {total_params}\")\n",
    "print(f\"Trainable Parameters: {trainable_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bef213f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "ROUGE 1 Score : 0.5084745762711865\n",
      "ROUGE 2 Score : 0.3620689655172414\n",
      "ROUGE L Score : 0.44067796610169496\n",
      "BLEU Score : 0.3520696440183301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "rouge_1 = []\n",
    "rouge_2 = []\n",
    "rouge_L = []\n",
    "bleu_val = []\n",
    "\n",
    "# Initialize the summarizer once outside the loop\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "for i in range(1000):  \n",
    "\n",
    "    try:  \n",
    "        # Generate the summary\n",
    "        summary = summarizer(df_test['article'].iloc[i])\n",
    "        # Print the summary\n",
    "        generated_summary = summary[0]['summary_text']\n",
    "        \n",
    "        # Compute ROUGE score\n",
    "        rouge_score = rouge.compute(predictions=[generated_summary], references=[df_test['highlights'].iloc[i]], use_aggregator=True)\n",
    "        rouge_1.append(rouge_score[\"rouge1\"])\n",
    "        rouge_2.append(rouge_score[\"rouge2\"])\n",
    "        rouge_L.append(rouge_score[\"rougeL\"])\n",
    "\n",
    "        # Compute BLEU score\n",
    "        bleu_score = bleu.compute(predictions=[generated_summary], references=[[df_test['highlights'].iloc[i]]])\n",
    "        bleu_val.append(bleu_score[\"bleu\"])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "print(f\"ROUGE 1 Score : {np.average(rouge_1)}\")\n",
    "print(f\"ROUGE 2 Score : {np.average(rouge_2)}\")\n",
    "print(f\"ROUGE L Score : {np.average(rouge_L)}\")\n",
    "print(f\"BLEU Score : {np.average(bleu_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30971a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By . Associated Press . PUBLISHED: . 14:11 EST, 25 October 2013 . | . UPDATED: . 15:36 EST, 25 October 2013 . The bishop of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A virus in late September and early October. The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion. Bishop John Folda (pictured) of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members in Fargo, Grand Forks and Jamestown to the hepatitis A . State Immunization Program Manager Molly Howell says the risk is low, but officials feel it's important to alert people to the possible exposure. The diocese announced on Monday that Bishop John Folda is taking time off after being diagnosed with hepatitis A. The diocese says he contracted the infection through contaminated food while attending a conference for newly ordained bishops in Italy last month. Symptoms of hepatitis A include fever, tiredness, loss of appetite, nausea and abdominal discomfort. Fargo Catholic Diocese in North Dakota (pictured) is where the bishop is located .\n",
      "Bishop John Folda, of North Dakota, is taking time off after being diagnosed .\n",
      "He contracted the infection through contaminated food in Italy .\n",
      "Church members in Fargo, Grand Forks and Jamestown could have been exposed .\n",
      "Bishop John Folda of the Fargo Catholic Diocese in North Dakota has exposed potentially hundreds of church members to the hepatitis A virus in late September and early October . The state Health Department has issued an advisory of exposure for anyone who attended five churches and took communion .\n"
     ]
    }
   ],
   "source": [
    "# Initialize the summarizer once outside the loop\n",
    "summarizer = pipeline(\"summarization\", model=model, tokenizer=tokenizer)\n",
    "summary = summarizer(df_test['article'].iloc[0])\n",
    "generated_summary = summary[0]['summary_text']\n",
    "        \n",
    "print(df_test['article'].iloc[0])\n",
    "print(df_test['highlights'].iloc[0])\n",
    "print(generated_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b7deba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
